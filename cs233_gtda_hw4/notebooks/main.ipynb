{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jitting Chamfer 3D\n",
      "Loaded JIT 3D CUDA chamfer distance\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import tqdm\n",
    "import matplotlib.pylab as plt\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from collections import defaultdict\n",
    "\n",
    "## Imports based on our ready-to-use code (after you pip-install the cs233_gtda_hw4 package)\n",
    "from cs233_gtda_hw4.in_out.utils import make_data_loaders\n",
    "from cs233_gtda_hw4.in_out.utils import save_state_dicts, load_state_dicts\n",
    "from cs233_gtda_hw4.in_out import pointcloud_dataset\n",
    "from cs233_gtda_hw4.in_out.plotting import plot_3d_point_cloud\n",
    "\n",
    "\n",
    "## Imports you might use if you follow are scaffold code (it is OK to use your own stucture of the models)\n",
    "from cs233_gtda_hw4.models import PointcloudAutoencoder\n",
    "from cs233_gtda_hw4.models import PartAwarePointcloudAutoencoder\n",
    "from cs233_gtda_hw4.models.point_net import PointNet\n",
    "from cs233_gtda_hw4.models.mlp import MLP\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Fixed Settings (we do not expect you to change these)\n",
    "## \n",
    "\n",
    "n_points = 1024  # number of points of each point-cloud\n",
    "n_parts = 4      # max number of parts of each shape\n",
    "n_train_epochs = 400\n",
    "\n",
    "# Students: feel free to change below -ONLY- for the bonus Question:\n",
    "# I.e., use THESE hyper-parameters when you train for the non-bonus questions.\n",
    "\n",
    "part_lambda = 0.005  # for the part-aware AE you will be using (summing) two losses:\n",
    "                     # chamfer + cross-entropy\n",
    "                     # do it like this: chamfer + (part_lambda * cross-entropy), \n",
    "                     # i.e. scale-down the cross-entropy\n",
    "init_lr = 0.009  # initial learning-rate, tested by us with ADAM optimizer (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Students: feel free to change below:\n",
    "\n",
    "# batch-size of data loaders\n",
    "batch_size = 128 # if you can keep this too as is keep it, \n",
    "                 # but if it is too big for your GPU, feel free to change it.\n",
    "\n",
    "# which device to use: cpu or cuda?\n",
    "device = 'cuda'  # Note: only the \"alternative\" (slower) chamfer_loss in losses/nn_distance can run in cpu.\n",
    "\n",
    "top_in_dir = '../data/'\n",
    "top_out_dir = '../data/out/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-examples train 750\n",
      "N-examples test 150\n",
      "N-examples val 50\n"
     ]
    }
   ],
   "source": [
    "# PREPARE DATA:\n",
    "\n",
    "loaders = make_data_loaders(top_in_dir, batch_size)\n",
    "\n",
    "for split, loader in loaders.items():\n",
    "    print('N-examples', split, len(loader.dataset))\n",
    "    \n",
    "### Student on your own:\n",
    "\n",
    "# encoder = PointNet...\n",
    "# decoder = MLP...\n",
    "# part_classifier = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_aware_model = True # or False\n",
    "\n",
    "if part_aware_model:\n",
    "    xentropy = nn.CrossEntropyLoss()\n",
    "#     model = PartAwarePointcloudAutoencoder().to(device) # Students Work here\n",
    "    model_tag = 'part_pc_ae'\n",
    "else:\n",
    "#     model = PointcloudAutoencoder().to(device)  # Students Work here\n",
    "    model_tag = 'pc_ae'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.Adam(model.parameters(), lr=init_lr)  # Students uncomment once you have defined your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:00<00:00, 929485.65it/s]\n"
     ]
    }
   ],
   "source": [
    "## Train for multiple epochs your model.\n",
    "# Students: the below for-loops are optional, feel free to structure your training \n",
    "# differently.\n",
    "\n",
    "min_val_loss = np.Inf\n",
    "out_file = osp.join(top_out_dir, model_tag + 'best_model.pth')\n",
    "start_epoch = 1\n",
    "\n",
    "for epoch in tqdm.tqdm(range(start_epoch, start_epoch + n_train_epochs)):\n",
    "    for phase in ['train', 'val', 'test']:\n",
    "        pass\n",
    "        \n",
    "        # Students Work Here.\n",
    "        # epoch_losses = model.train_for_one_epoch  ... \n",
    "\n",
    "##       Save model if validation loss improved.\n",
    "#         if phase == 'val' and recon_loss < min_val_loss:\n",
    "#             min_val_loss = recon_loss\n",
    "            \n",
    "##        If you save the model like this, you can use the next peace to load it. \n",
    "#             save_state_dicts(out_file, epoch=epoch, model=model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model with best per-validation loss (uncomment when ready)\n",
    "# best_epoch = load_state_dicts(out_file, model=model)\n",
    "# print('per-validation optimal epoch', best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE your plots and analysis\n",
    "\n",
    "# 5 examples to visualize per questions (e, f)\n",
    "examples_to_visualize = ['8a67fd47001e52414c350d7ea5fe2a3a',\n",
    "                         '1e0580f443a9e6d2593ebeeedbff73b',\n",
    "                         'd3562f992aa405b214b1fd95dbca05',\n",
    "                         '4e8d8792a3a6390b36b0f2a1430e993a',\n",
    "                         '58479a7b7c157865e68f66efebc71317']\n",
    "\n",
    "# You can (also) use the function for the reconstructions or the part-predictions \n",
    "# (for the latter check the kwargs parameter 'c' of matplotlib.\n",
    "    # plot_3d_point_cloud, eg. try plot_3d_point_cloud(loaders['test'].dataset.pointclouds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last, save the latent codes of the test data and go to the \n",
    "# measuring_part_awareness and tsne_plot_with_latent_codes code.\n",
    "\n",
    "model.eval()   # Do not forget this.! We are not training any more (OK, since we do not \n",
    "               # have batch-norm, drop-out etc. this is not so important, however it is good standard \n",
    "               # practice)\n",
    "latent_codes = []\n",
    "\n",
    "# Extract the latent codes and save them, so you can analyze them later.\n",
    "\n",
    "np.savez(osp.join(top_out_dir, model_tag +'_latent_codes'), \n",
    "         latent_codes=latent_codes, \n",
    "         test_names=test_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joint36",
   "language": "python",
   "name": "joint36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
